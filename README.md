# Em contru√ß√£o

# Tutorial Arquitetura Hexagonal - CRUD de Usu√°rios | API + MongoDB (NoSQL) + Kafka (Mensageria)

Aprenda na pr√°tica como aplicar a **Arquitetura Hexagonal** em microsservi√ßos utilizando **Java**, **Spring Boot**, **MongoDB** e **Kafka**.

Neste projeto, construiremos um **CRUD de Clientes**, explorando todas as camadas da arquitetura de forma clara e orientada.

### **Rode a aplica√ß√£o**

Acesse o arquivo HexagonalApplicationTests.java:
Em src/test/java/com/example/hexagonal/HexagonalApplicationTests.java
Execute pela IDE (clique no bot√£o de "Run Application")

ou

Voc√™ pode executar diretamente com o Maven:

```bash
mvn spring-boot:run
```

sua aplica√ß√£o est√° todando na porta:
http://localhost:8080

Aparecer√°: üöÄ API Hexagonal est√° no ar!

### **Subir o MongoDB com Docker**

No terminal, dentro da pasta `docker-local`, rode:

```bash
docker-compose up -d
```

## Rodar o test

```bash
mvn test
```

ou dar um run em src/main/java/com/example/hexagonal/HexagonalApplication.java

## üß™ Verifique se est√° tudo certo

MongoDB rodando em `localhost:27017`

Voc√™ pode acessar o Mongo Express em:

```
http://localhost:8081
```

Perfeito! Seu `docker-compose.yml` est√° configurado para usar autentica√ß√£o com:

-   **Usu√°rio:** `root`
-   **Senha:** `123456789`
-   **Host:** `localhost` (porta `27017` mapeada para o container)

# Testes:

### üß™ Usando `curl` (linha de comando)

```bash
curl -X POST http://localhost:8080/api/v1/customers \
  -H "Content-Type: application/json" \
  -d '{
        "name": "Jo√£o Silva",
        "cpf": "12345678900",
        "zipCode": "01001-000"
      }'
```

Para visualizar a lista de clientes, use no navegador

```bash
http://localhost:8080/api/v1/customers
```

---

# Tutorial: Usando Confluent Kafka com VSCode e Spring Boot

## ‚úÖ **Vis√£o Geral da Aplica√ß√£o**

A aplica√ß√£o simula o fluxo de cadastro e valida√ß√£o de clientes usando arquitetura hexagonal, Kafka e MongoDB. O processo √© dividido em APIs separadas:

-   **API de Cliente**: recebe dados do cliente, salva no banco e envia o CPF para valida√ß√£o via Kafka.
-   **API de Endere√ßo**: retorna dados do endere√ßo a partir do CEP.
-   **API de Valida√ß√£o de CPF**: consome o CPF do Kafka, valida e devolve a resposta tamb√©m via Kafka.
-   **MongoDB**: armazena os dados dos clientes.
-   **Kafka**: canal de comunica√ß√£o ass√≠ncrona entre os servi√ßos.

![Kafka Diagrama](./doc/kafka.png)

O fluxo segue:

1. API de cliente envia CPF para Kafka.
2. API de valida√ß√£o consome o CPF e devolve dados validados no outro t√≥pico.
3. A API de cliente escuta esse segundo t√≥pico e atualiza no banco.
4. Toda comunica√ß√£o entre sistemas √© desacoplada, via t√≥picos Kafka.

---

**tutorial completo passo a passo** para rodar Kafka com Spring Boot usando Docker e visualizar tudo com o **Kafka UI** (interface web moderna).

---

# ‚úÖ Tutorial Completo: Spring Boot + Kafka + Kafka UI com Docker

---

## ‚öôÔ∏è 1. `docker-compose.yml`

Atualize o arquivo
docker-local/docker-compose.yml

```yml
version: "3"

services:
    mongo:
        image: mongo
        environment:
            MONGO_INITDB_ROOT_USERNAME: root
            MONGO_INITDB_ROOT_PASSWORD: 123456789
        ports:
            - "27017:27017"
        # volumes:
        #   - /home/hexagonal/Desenvolvimento/Docker/Volumes/MongoDB:/data/db
        networks:
            - hexagonal-network

    mongo-express:
        image: mongo-express
        ports:
            - 8081:8081
        environment:
            ME_CONFIG_BASICAUTH_USERNAME: root
            ME_CONFIG_BASICAUTH_PASSWORD: 123456789
            ME_CONFIG_MONGODB_ADMINUSERNAME: root
            ME_CONFIG_MONGODB_ADMINPASSWORD: 123456789
            ME_CONFIG_MONGODB_URL: mongodb://root:123456789@mongo:27017/
        networks:
            - hexagonal-network

    zookeeper:
        image: bitnami/zookeeper:latest
        ports:
            - "2181:2181"
        environment:
            - ALLOW_ANONYMOUS_LOGIN=yes
        networks:
            - hexagonal-network

    kafka:
        image: bitnami/kafka:3.4.0
        ports:
            - "9092:9092"
        environment:
            - KAFKA_ENABLE_KRAFT=no # <--- ESSENCIAL!
            - KAFKA_BROKER_ID=1
            - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
            - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
            - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
            - ALLOW_PLAINTEXT_LISTENER=yes
        depends_on:
            - zookeeper
        networks:
            - hexagonal-network

    kafka-ui:
        image: provectuslabs/kafka-ui
        ports:
            - "9080:8080"
        environment:
            - KAFKA_CLUSTERS_0_NAME=hexagonal
            - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
        depends_on:
            - kafka
        networks:
            - hexagonal-network

networks:
    hexagonal-network:
        driver: bridge
```

---

## üöÄ 2. Subir o ambiente com Docker

No terminal, execute:

```bash
docker-compose up -d
```

### üîç Acessando o Kafka UI

Depois, acesse o Kafka UI: [http://localhost:9080](http://localhost:9080)

Abra no navegador:

```
http://localhost:9080
```

-   Voc√™ ver√° o cluster com nome `hexagonal`.
-   Navegue pelos **t√≥picos**, **consumidores**, **brokers** e **mensagens**.
-   Pode **criar t√≥picos** como `tp-cpf-validation` diretamente na interface.

Para **criar um t√≥pico no Kafka UI** com o nome `tp-cpf-validation`, siga este passo a passo no navegador:

---

### ‚úÖ Passos para Criar o T√≥pico `tp-cpf-validation` no Kafka UI

1. **Acesse o Kafka UI**:
   Abra [http://localhost:9080](http://localhost:9080) no navegador.

2. **No menu lateral**, clique em **"Topics"**.

3. No canto superior direito, clique em **"add a topic"**.

4. Preencha o formul√°rio da seguinte maneira:

    - **Topic Name**:
      `tp-cpf-validation`

    - **Number of Partitions**:
      `1` (ou mais, se quiser paralelismo; geralmente `1` para testes)

    - **Replication Factor**:
      `1` (se voc√™ tiver s√≥ um broker, esse √© o valor correto)

    - **Cleanup policy**:
      `Delete` (padr√£o; remove mensagens ap√≥s o tempo definido)

    - **Time to retain data (in ms)**:
      Escolha, por exemplo, `7 days` (ou o tempo que fizer sentido pro seu caso)

    - **Max size on disk in GB**:
      Pode deixar como **Not Set** (sem limite)

    - **Maximum message size in bytes**:
      Deixe em branco, a menos que queira configurar um limite

    - **Custom parameters**:
      Ignore por enquanto, a menos que queira configurar propriedades espec√≠ficas

5. Clique em **"Create Topic"** no final do formul√°rio.

---

Ap√≥s isso, o t√≥pico `tp-cpf-validation` estar√° criado e vis√≠vel na lista de t√≥picos. Voc√™ poder√° clicar nele para ver mensagens, produzir eventos, visualizar consumidores, etc.

---

---

## üåê 4. Configurar Spring Boot

Confirme se j√° est√° instalado

### Depend√™ncias no `pom.xml`:

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

---

### Arquivo `application.properties`:

```
seu-projeto/
‚îú‚îÄ‚îÄ docker-local/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ main/
‚îÇ       ‚îú‚îÄ‚îÄ java/...
‚îÇ       ‚îî‚îÄ‚îÄ resources/
‚îÇ           ‚îî‚îÄ‚îÄ application.properties

```

atualize

```bash
spring.application.name=hexagonal
# MongoDB
spring.data.mongodb.uri=mongodb://root:123456789@localhost:27017
spring.data.mongodb.database=hexagonal_db
logging.level.org.springframework.web=DEBUG

# Kafka
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.consumer.group-id=hexagonal-consumer-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# Cria√ß√£o autom√°tica de t√≥picos (opcional)
spring.kafka.admin.auto-create=true
```

Para que serve esse bloco no application.properties?
Essas configura√ß√µes servem para informar ao Spring Boot como se comunicar com o Apache Kafka, tanto para enviar quanto para receber mensagens.
PRODUTOR (Producer) Usado para ENVIAR mensagens para um t√≥pico Kafka
CONSUMIDOR (Consumer) Usado para LER mensagens de um t√≥pico Kafka

### üß™ Testando no Spring Boot

Crie um `Producer` e um `Consumer` e envie mensagens para o t√≥pico que voc√™ criou. Voc√™ ver√° essas mensagens aparecendo no `Kafka UI`.

---

## üß± 1. Configurar KafkaConsumerConfig e KafkaProducerConfig

### Classe de configura√ß√£o `KafkaConsumerConfig.java`:

### Classe `KafkaConsumerConfig.java`:

Essa classe serve para configurar um consumer customizado no Spring Boot, especialmente para deserializar mensagens em objetos Java (CustomerMessage).
Isso quer dizer: quando a mensagem chegar, transforme o JSON direto em um objeto CustomerMessage.
Voc√™ usar√° isso quando a aplica√ß√£o principal receber os dados j√° validados (CPF, CEP, nome...) da "API externa de valida√ß√£o", via outro t√≥pico Kafka.

src/main/java/com/example/hexagonal/config/KafkaApplication.java

```java
import com.arantes.hexagonal.adapters.in.consumer.message.CustomerMessage;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

import static org.apache.kafka.clients.consumer.ConsumerConfig.AUTO_OFFSET_RESET_CONFIG;
import static org.apache.kafka.clients.consumer.ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG;
import static org.apache.kafka.clients.consumer.ConsumerConfig.GROUP_ID_CONFIG;
import static org.apache.kafka.clients.consumer.ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG;
import static org.apache.kafka.clients.consumer.ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG;

@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Bean
    public ConsumerFactory<String, CustomerMessage> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(GROUP_ID_CONFIG, "example");
        props.put(KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        props.put(AUTO_OFFSET_RESET_CONFIG, "earliest");
        return new DefaultKafkaConsumerFactory<>(props, new StringDeserializer(), new JsonDeserializer<>(CustomerMessage.class));
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, CustomerMessage> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, CustomerMessage> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }

}
```

Antes de criar a configura√ß√£o do consumidor, vamos criar um objeto que ir√° consumir o t√≥pico para atualizar o cadastro do cliente.

Acesse e crie o ConsumerMessage.java dentro da pasta consumer/message

src/main/java/com/example/hexagonal/infrastructure/adapter/input/consumer/message/CustomerMessage.java

Este ser√° o objeto que vou receber l√° do kafta para atualizar os dados do cliente

```java
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class CustomerMessage {

    private String id;

    private String name;

    private String zipCode;

    private String cpf;

    private Boolean isValidCpf;

}
```

iremos pegar esses dados e alterar no cadastro do cliente.
A id√©ia aqui √© enviar para t√≥pico do kafka o cpf e a aplica√ßao fict√≠cia simular a valida√ß√£o do cpf retornando peo id do do cliente, comnome e o cep junto com o cpf tamb√©m, falando se √© v√°lido ou n√£o.

### Classe de configura√ß√£o `KafkaProducerConfig.java`:

### Classe `KafkaProducerConfig.java`:

@Configuration
Diz ao Spring que esta classe cont√©m beans (objetos gerenciados) que devem ser carregados no contexto da aplica√ß√£o.
O m√©todo cria um ProducerFactory, que √© respons√°vel por criar produtores Kafka com as configura√ß√µes definidas.

src/main/java/com/example/hexagonal/config/KafkaProducerConfig.java

```java
package com.arantes.hexagonal.config;

import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

import static org.apache.kafka.clients.consumer.ConsumerConfig.GROUP_ID_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.BOOTSTRAP_SERVERS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG;
import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;

@Configuration
public class KafkaProducerConfig {

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
        configProps.put(GROUP_ID_CONFIG, "example");
        configProps.put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

}
```

## üß± 2. Implementar o produtor e o consumidor

A ideia seria:
1- Inserir os dados do cliente na api principal
2- Buscamos os dados do endere√ßo na api CEP externa
3- Salvamos na base dados no MongoDB
4- Enviar um cpf do cliente para uma fila do kafka
5- A Api externa CPF vai consumir a fila do kafka: ler o cpf, fazer as valida√ß√µes necess√°rias
6- A Api externa CPF vai postar em outra fila os dados corretos do cliente
7- A Api principal ir√° consumir os dados corretos do cliente que ir√° ler do t√≥pico e dar update no cadastro do cliente

---

## Producer - Parate do envio do cpf para kafka

Vamos inciar criando o produtor com o cpf que enviar√° para fila do kafka:

vamos acessar o usecase CreateCustomerUseCase.java
src/main/java/com/example/hexagonal/application/usecase/CreateCustomerUseCase.java

Em CreateCustomerUseCase.java precisamos enviar daods para uma fila do kafka

Assim, precisamos criar uma porta de sa√≠da para enviar a mensagem para o textrior (fila do kafka)

Como a responsabilidade da porta √© enviar o CPF para valida√ß√£o externa, o nome da interface deve refletir o que a aplica√ß√£o precisa que seja feito, sem se preocupar com como isso ser√° implementado.

Sugest√£o de nome claro e expressivo: SendCpfForValidationOutputPort
Melhor nome para a implementa√ß√£o (Adaptador):SendCpfForValidationKafkaAdapter

```text
hexagonal/
‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îî‚îÄ‚îÄ port/
‚îÇ       ‚îî‚îÄ‚îÄ output/
‚îÇ           ‚îî‚îÄ‚îÄ SendCpfForValidationOutputPort.java
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îî‚îÄ‚îÄ messaging/
‚îÇ       ‚îî‚îÄ‚îÄ kafka/
‚îÇ           ‚îî‚îÄ‚îÄ SendCpfForValidationKafkaAdapter.java
```

Nome da interface: focado no o que (a√ß√£o de neg√≥cio que precisa ser feita).
Nome do adaptador: focado no como (implementa√ß√£o t√©cnica espec√≠fica).
Isso mant√©m o sistema limpo, test√°vel e desacoplado de detalhes t√©cnicos.

```java
public class CreateCustomerUseCase implements CreateCustomerInputPort {

    private final AddressLookupOutputPort addressLookupOutputPort;
    private final CustomerPersistenceOutputPort customerPersistenceOutputPort;
    private final SendCpfForValidationOutputPort sendCpfForValidationOutputPort;

    public CreateCustomerUseCase(AddressLookupOutputPort addressLookupOutputPort,
            CustomerPersistenceOutputPort customerPersistenceOutputPort, SendCpfForValidationOutputPort sendCpfForValidationOutputPort) {
        this.addressLookupOutputPort = addressLookupOutputPort;
        this.customerPersistenceOutputPort = customerPersistenceOutputPort;
        this.sendCpfForValidationOutputPort = sendCpfForValidationOutputPort;

    }

    // this.cpfValidationMessagePort = cpfValidationMessagePort;

    public void create(Customer customer, String zipCode) {
        System.out.println("üéØ Entrou CreateCustomerUseCase: ");
        var address = addressLookupOutputPort.findByZipCode(zipCode);
        System.out.println("üéØ address: " + address.getCity());
        customer.setAddress(address);
        System.out.println("üéØ Entrou CreateCustomerUseCase: " + customer.show());
        customerPersistenceOutputPort.save(customer);
        // cpfValidationMessagePort.sendCpfForValidation(customer.getCpf());
        sendCpfForValidationOutputPort.send(customer.getCpf());
    }

}
```

Assim adiiconamos no usecase por inje√ß√£o de dpend√™ncia a porta de sa√≠da e o m√©tood de envio

Agora precisamos da interface e do adaptador:

### Interface do Produtor `SendCpfForValidationOutputPort.java`:

```java
package com.arantes.hexagonal.application.ports.out;

public interface SendCpfForValidationOutputPort {

    void send(String cpf);

}
```

### Implementa√ß√£o da classe concreta do Produtor `SendCpfForValidationKafkaAdapter.java`:

criaremos o adapter em kafka/SendCpfForValidationKafkaAdapter.java

```text
hexagonal/
‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îî‚îÄ‚îÄ port/
‚îÇ       ‚îî‚îÄ‚îÄ output/
‚îÇ           ‚îî‚îÄ‚îÄ SendCpfForValidationOutputPort.java
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îî‚îÄ‚îÄ adapter/
‚îÇ         ‚îî‚îÄ‚îÄ output/
‚îÇ                 ‚îî‚îÄ‚îÄ kafka/
‚îÇ                      ‚îî‚îÄ‚îÄ SendCpfForValidationKafkaAdapter.java
```

```java
package com.arantes.hexagonal.adapters.out;

import com.arantes.hexagonal.application.ports.out.SendCpfForValidationOutputPort;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class SendCpfForValidationAdapter implements SendCpfForValidationOutputPort {

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    @Override
    public void send(String cpf) {
        kafkaTemplate.send("tp-cpf-validation", cpf);
    }

}
```

Envio para o kafka
Basicamente injetamos o kafka template
por par√¢metros enviamos o t√≥pico e os dados

Precisamos atualizar o bean:

src/main/java/com/example/hexagonal/config/CreateCustomerConfig.java

```java
@Configuration
public class CreateCustomerConfig {

    @Bean
    public CreateCustomerUseCase createCustomerUseCase(
            ViaCepAddressAdapter viaCepAddressAdapter,
            MongoCustomerRepositoryAdapter mongoCustomerRepositoryAdapter,
            SendCpfForValidationAdapter sendCpfForValidationAdapter) {
        return new CreateCustomerUseCase(viaCepAddressAdapter, mongoCustomerRepositoryAdapter, sendCpfForValidationAdapter);
    }

}
```

## Consumer

Agora criaremos o consumidor

```text
hexagonal/
‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îî‚îÄ‚îÄ port/
‚îÇ       ‚îî‚îÄ‚îÄ output/
‚îÇ           ‚îî‚îÄ‚îÄ SendCpfForValidationOutputPort.java
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îî‚îÄ‚îÄ adapter/
‚îÇ         ‚îî‚îÄ‚îÄ input/
‚îÇ                 ‚îî‚îÄ‚îÄ consumer/
‚îÇ                       ‚îî‚îÄ‚îÄ ReceuveValidatedCpfConsumer.java
‚îÇ
```

### Consumidor `ReceuveValidatedCpfConsumer.java`:

Precisamso receber a mensagem que vir√° do kafka

```java
//package com.arantes.hexagonal.adapters.in.consumer;

import com.arantes.hexagonal.adapters.in.consumer.mapper.CustomerMessageMapper;
import com.arantes.hexagonal.adapters.in.consumer.message.CustomerMessage;
import com.arantes.hexagonal.application.ports.in.UpdateCustomerInputPort;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class ReceiveValidatedCpfConsumer {

    @Autowired
    private UpdateCustomerInputPort updateCustomerInputPort;

    @Autowired
    private CustomerMessageMapper customerMessageMapper;

    @KafkaListener(topics = "tp-cpf-validated", groupId = "example")
    public void receive(CustomerMessage customerMessage) {
        var customer = customerMessageMapper.toCustomer(customerMessage);
        updateCustomerInputPort.update(customer, customerMessage.getZipCode());
    }

}
```

Temos que criar o mapper:

```java
package com.arantes.hexagonal.adapters.in.consumer.mapper;

import com.arantes.hexagonal.adapters.in.consumer.message.CustomerMessage;
import com.arantes.hexagonal.application.core.domain.Customer;
import org.mapstruct.Mapper;
import org.mapstruct.Mapping;

@Mapper(componentModel = "spring")
public interface CustomerMessageMapper {

    @Mapping(target = "address", ignore = true)
    Customer toCustomer(CustomerMessage customerMessage);

}
```

√© necess√°rio implementar o updateCustomerInputPort

---

## üß™ 5. Rodando tudo

Voc√™ pode:

1. Rodar o app com `mvn spring-boot:run`
2. Enviar dados do cliente via post em `http://localhost:8081/api/v1/customers`
3. visualizar a lista de clientes no navegador http://localhost:8080/api/v1/customers
4. Acessar o banco de dadod do mongodb em http://localhost:8081 via Mongo Express
5. Buscar o cliente por id http://localhost:8080/api/v1/customers/colar o id
6. Acessar o kafka no navegador http://localhost:9080/ e verificar se foi enviado ( mostra s√≥ o bin√°rio)
7. Testar o update em `http://localhost:8081/api/v1/customers`
8. Testar a mensagem do kafka do cpf validado no t√≥pico tc-cpf-validated porque o nosso consumidor fica escultando
   (basta publicar a mensagem - publish single message ) Muda-se o cep e que o cpf est√° validado
9. Testar a dele√ß√£o do cliente

### üß™ Usando `curl` (linha de comando)

```bash
curl -X POST http://localhost:8080/api/v1/customers \
  -H "Content-Type: application/json" \
  -d '{
        "name": "Jo√£o Silva",
        "cpf": "12345678900",
        "zipCode": "01001-000"
      }'
```

Para visualizar a lista de clientes, use no navegador

```bash
http://localhost:8080/api/v1/customers
```

MongoDB rodando em `localhost:27017`

Voc√™ pode acessar o Mongo Express em:

```
http://localhost:8081
```

Perfeito! Seu `docker-compose.yml` est√° configurado para usar autentica√ß√£o com:

-   **Usu√°rio:** `root`
-   **Senha:** `123456789`
-   **Host:** `localhost` (porta `27017` mapeada para o container)

---

## ‚úÖ Pronto!

Voc√™ agora tem um ambiente **Kafka completo** com Spring Boot e interface moderna.

## Extras:

For√ßar remo√ß√£o limpando todas as redes e volumes
docker compose down --volumes --remove-orphans
docker network prune -f

docker compose down --volumes --remove-orphans
docker network prune -f

## Biblioteca archunit

https://www.archunit.org/userguide/html/000_Index.html

### Definindo acessos entre camadas

Teste para verificar que somente a camada de config poder√° acessar a camada de adapatadores
Assim s√≥ vamos permitir que acesse somnete a cadamada de dadapatadores a camada de configura√ß√£o

### Garantindo que as classes estejam nos pacotes corretos

### Garantindo que um pacote tenha determinado sufixo

## ‚úÖ **Vantagens da Arquitetura Usada**

### 1. üîå **Baixo acoplamento com Kafka (Hexagonal)**

-   A l√≥gica de neg√≥cio (dom√≠nio) **n√£o depende diretamente** do Kafka.
-   Se amanh√£ voc√™ quiser trocar Kafka por RabbitMQ, HTTP, ou gRPC, **s√≥ troca o adaptador** (`SendCpfForValidationKafkaAdapter`), sem mexer na regra de neg√≥cio.
-   Isso permite **testes unit√°rios limpos**, pois os adaptadores s√£o "plug√°veis".

---

### 2. üß± **Separa√ß√£o de responsabilidades (Single Responsibility)**

-   Cada camada ou componente tem uma fun√ß√£o clara:

    -   **Use Cases** cuidam da l√≥gica.
    -   **Ports** definem contratos.
    -   **Adapters** implementam detalhes t√©cnicos.

Isso facilita **manuten√ß√£o, testes e legibilidade** do c√≥digo.

---

### 3. üîÅ **Comunica√ß√£o ass√≠ncrona com Kafka**

-   Kafka permite **alta escalabilidade e resili√™ncia**.
-   Um servi√ßo publica o CPF sem precisar esperar a valida√ß√£o terminar.
-   A valida√ß√£o pode acontecer depois (em milissegundos ou segundos), sem travar o fluxo.
-   Ideal para sistemas distribu√≠dos ou com **baixa lat√™ncia esperada**.

---

### 4. üîÄ **Toler√¢ncia a falhas**

-   Se a API de valida√ß√£o de CPF estiver fora do ar, a mensagem Kafka continua no t√≥pico.
-   Quando ela voltar, ela l√™ a fila e processa.
-   Evita perda de dados e garante **resili√™ncia**.

---

### 5. üåê **Escalabilidade**

-   Cada microservi√ßo (Cliente, Endere√ßo, Valida√ß√£o de CPF) pode ser escalado **de forma independente**.
-   Kafka pode lidar com milhares de mensagens por segundo, com m√∫ltiplos consumidores processando em paralelo (parti√ß√µes).

---

### 6. üë®‚Äçüîß **F√°cil de testar e evoluir**

-   Como cada porta/adaptador √© separado:

    -   Pode-se **mockar** portas em testes.
    -   Substituir adaptadores conforme o ambiente (ex: produ√ß√£o vs testes).

---

### 7. üìà **Observabilidade e rastreabilidade**

-   Kafka UI permite **visualizar mensagens trocadas** entre sistemas.
-   F√°cil rastrear o que foi enviado, consumido, e quando.

---

## ‚ùóPoss√≠veis Desvantagens (para comparar)

| Item                           | Risco/Ponto de Aten√ß√£o                                                                |
| ------------------------------ | ------------------------------------------------------------------------------------- |
| ‚öôÔ∏è Complexidade inicial        | Arquitetura hexagonal e Kafka adicionam complexidade para times iniciantes.           |
| üß™ Testes integrados           | Requer mais cuidado para testar comunica√ß√£o Kafka (embora possa usar testcontainers). |
| ‚åõ Lat√™ncia de atualiza√ß√£o     | Comunica√ß√£o ass√≠ncrona pode levar alguns milissegundos a mais para refletir o dado.   |
| üì¶ Manuten√ß√£o de t√≥picos Kafka | Exige conhecimento de configura√ß√£o, particionamento, reten√ß√£o de mensagens etc.       |

---

## üéØ Quando **vale muito a pena** usar essa arquitetura:

-   Voc√™ espera **crescimento futuro** da aplica√ß√£o (escalabilidade).
-   Quer manter sua **regra de neg√≥cio desacoplada de detalhes t√©cnicos**.
-   Precisa de **integra√ß√£o entre sistemas ou microsservi√ßos**.
-   Valoriza **resili√™ncia**, **toler√¢ncia a falhas** e **mensageria confi√°vel**.

---

## üéØ **O Kafka foi √∫til neste cen√°rio?**

### ‚úÖ **Sim, o Kafka foi √∫til se voc√™ quer:**

1. **Desacoplamento entre servi√ßos**

    - A **API de Cliente** e a **API de Valida√ß√£o de CPF** **n√£o se conhecem diretamente**.
    - A comunica√ß√£o entre elas √© feita por meio de t√≥picos Kafka, o que permite que:

        - Uma envie a mensagem e esque√ßa (`fire and forget`);
        - A outra consuma quando estiver pronta.

2. **Simular ambiente de microsservi√ßos reais**

    - Em sistemas distribu√≠dos (como microservi√ßos), **mensageria ass√≠ncrona** via Kafka √© uma pr√°tica recomendada.
    - Voc√™ simula cen√°rios reais: valida√ß√£o ass√≠ncrona, servi√ßos isolados, falhas toleradas, etc.

3. **Maior resili√™ncia e escalabilidade**

    - Se a API de valida√ß√£o de CPF estiver fora do ar, a mensagem fica no t√≥pico at√© que ela volte e consuma.
    - Isso **aumenta a confiabilidade** da aplica√ß√£o como um todo.

---

### ‚ùå **Mas o Kafka pode ser ‚Äúoverkill‚Äù se:**

1. **Tudo est√° no mesmo servi√ßo**

    - Se as APIs de cliente e valida√ß√£o est√£o no **mesmo monolito ou servi√ßo**, usar Kafka pode ser **complexo demais para pouco ganho**.
    - Um simples `@Service` chamando o outro resolveria o problema com menos esfor√ßo.

2. **A valida√ß√£o precisa ser imediata**

    - Kafka √© ass√≠ncrono. Se voc√™ **precisa validar o CPF e dar resposta imediata** para o usu√°rio, usar Kafka **atrapalha** em vez de ajudar.
    - Nesse caso, uma chamada HTTP entre servi√ßos seria mais apropriada.

3. **Seu sistema n√£o √© distribu√≠do ou escal√°vel**

    - Se voc√™ est√° construindo um projeto pequeno, did√°tico ou sem necessidade de escalar, Kafka pode adicionar **infraestrutura desnecess√°ria** (Zookeeper, Broker, configura√ß√µes etc).

---

## ‚úÖ **Conclus√£o:**

| Contexto                                   | Kafka foi √∫til? | Por qu√™?                                               |
| ------------------------------------------ | --------------- | ------------------------------------------------------ |
| Microservi√ßos desacoplados                 | ‚úÖ Sim          | Comunica√ß√£o entre sistemas com toler√¢ncia a falha      |
| Projeto acad√™mico ou estudo de arquitetura | ‚úÖ Sim          | Aprender Kafka, eventos, t√≥picos, consumers/producers  |
| Projeto monol√≠tico simples                 | ‚ùå N√£o          | Um `@Service` resolveria com menos complexidade        |
| Valida√ß√£o s√≠ncrona (resposta imediata)     | ‚ùå N√£o          | Kafka adiciona lat√™ncia e n√£o √© adequado para s√≠ncrono |

---

Se seu foco for **estudo de boas pr√°ticas de arquitetura moderna**, **Kafka vale muito a pena nesse cen√°rio**.
Se for s√≥ resolver o problema de valida√ß√£o de CPF rapidamente, talvez um `RestTemplate` ou `FeignClient` bastasse.

---
